{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xex9LS2hFrR0"
   },
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as any collaborators you worked with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "67N95kyHFrR2"
   },
   "outputs": [],
   "source": [
    "COLLABORATORS = \"HARSHUL GUPTA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zk-flzsPFrR4"
   },
   "source": [
    "## Numerical Methods for HJB Equations and Mean Field Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HiaN-3fWFrR4"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%precision 16\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "G4PIRBwsFrR5",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d32b4bf706b10b4d167573f34b78f1b7",
     "grade": false,
     "grade_id": "cell-c4123d20c3a14019",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Final Project\n",
    "\n",
    "This notebook will provide a brief structure and rubric for presenting your final project.\n",
    "\n",
    "The purpose of the project is 2-fold\n",
    "* To give you an opportunity to work on a problem you are truly interested in (as this is the best way to actually learn something)\n",
    "* To demonstrate to me that you understand the overall workflow of problem solving from problem selection to implementation to discussion\n",
    "\n",
    "You can choose any subject area that interests you as long as there is a computational component to it.  However, please do not reuse projects or homeworks you have done in other classes.  This should be **your** original work.\n",
    "\n",
    "**You can work in teams, but clearly identify each persons contribution** and every team member should hand in their own copy of the notebook.\n",
    "\n",
    "### Structure\n",
    "There are 5 parts for a total of 100 points that provide the overall structure of a mini research project.\n",
    "\n",
    "* Abstract\n",
    "* Introduction and Problem Description\n",
    "* Brief discussion of Computational approach and import of any additional packages\n",
    "* Implementation including tests\n",
    "* Discussion of results and future directions\n",
    "\n",
    "For grading purposes, please try to make this notebook entirely self contained.\n",
    "\n",
    "The project is worth about 2 problem sets and should be of comparable length (please: I will have about 100 of these to read and I am not expecting full 10 page papers).  The actual project does not necessarily have to work but in that case you should demonstrate that you understand why it did not work and what steps you would take next to fix it.\n",
    "\n",
    "Have fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "DbNVEkT3FrR5",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fbc13653b2b30717b82998dc8185d077",
     "grade": false,
     "grade_id": "cell-382e921cda790b91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Abstract [10 pts]\n",
    "\n",
    "Provide a 1-2 paragraph abstract of the project in the style of a research paper.  The abstract should contain\n",
    "\n",
    "* A brief description of the problem\n",
    "* A brief justification describing why this problem is important/interesting to you\n",
    "* A general description of the computational approach\n",
    "* A brief summary of what you did and what you learned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": true,
    "id": "wfVVWx6LFrR6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a13e715b5cd07bdd5e0f62ba3ffd3b70",
     "grade": true,
     "grade_id": "cell-2152ede583bdfd2e",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Abstract\r\n",
    "\r\n",
    "### A brief description of the problem\r\n",
    "The goal of this project is to review certain numerical methods proposed for the solution of Hamilton-Jacobi-Bellman (HJB) equations and their application to problems in Mean Field Games (MFG). This involves the derivation of finite difference methods and the analysis of partial differential equations modeling interactions between multiple agents.\r\n",
    "\r\n",
    "### A brief justification describing why this problem is important/interesting to you\r\n",
    "This topic is important because it forms the foundation of optimal control theory, which has broad applications in fields such as economics, finance, and social systems. The study of HJB equations in the context of MFGs is of particular interest to me, as it aligns with my passion for improving decision-making processes in complex, large-scale systems through applied mathematics.\r\n",
    "\r\n",
    "### A general description of the computational approach\r\n",
    "The computational approach explores a simplified version of MFGs through a Forward-Backward PDE system. We model the underlying process as a controlled diffusion and seek the optimal control `u` and the flow of probability densities `m` that satisfy both the HJB and Kolmogorov-Fokker-Planck (KFP) equations. The HJB equation is supplemented with a terminal condition, while the KFP equation is supplemented with an initial condition. The main challenge of the project arises from the forward-backward duality of the system, which is solved through Picard Fixed Point iterations.\r\n",
    "\r\n",
    "### A brief summary of what you did and what you learned\r\n",
    "In this work, I implemented and analyzed various numerical methods for solving these equations, including finite difference schemes for spatial and temporal discretization. The solution methodology alternates between solving the HJB and KFP equations using Picard iteration. I explored the convergence properties of these methods and observed how model parameters such as volatility and risk aversion influence the evolution of the solution. Through this process, I gained insights into both the numerical methods employed and the theoretical implications of the HJB and KFP system in MFGs.\r\n",
    "you learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "IP8SvTpbFrR6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a85e6fdaa77e6624fee7a062c4fbae2",
     "grade": false,
     "grade_id": "cell-318b53f4ed873060",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introduction [15 pts]\n",
    "\n",
    "In ~4-5 paragraphs, describe\n",
    "* The general problem you want to solve\n",
    "* Why it is important and what you hope to achieve.\n",
    "\n",
    "Please provide basic **references**, particularly if you are reproducing results from a paper. Also include any basic equations you plan to solve.\n",
    "\n",
    "Please use proper spelling and grammar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "n9PjGoDbFrR6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "389f9029792ef9416cb9a4531f47cfa0",
     "grade": true,
     "grade_id": "cell-f3a6a5fa3a14f053",
     "locked": false,
     "points": 13,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "### Introduction\r\n",
    "\r\n",
    "In this project, we focus on developing and implementing numerical methods for solving Hamilton-Jacobi-Bellman (HJB) equations, specifically within the context of Mean Field Games (MFGs). MFGs model the behavior of large populations of agents who make decisions based on both their own state and the statistical distribution of the states of other agents. Solving the coupled system of HJB and Kolmogorov-Fokker-Planck (KFP) equations that govern MFGs is a challenging problem due to their nonlinearity and the complexity of modeling interactions within large populations. By solving these equations numerically, we aim to improve the understanding of complex systems and decision-making processes in economics, social sciences, and other fields. \r\n",
    "\r\n",
    "This problem is important because MFGs have broad applications in areas like economics, finance, and social systems. By developing efficient numerical methods for solving the HJB equations in MFGs, we aim to contribute to the advancement of decision-making models in large-scale systems. This is particularly relevant to fields such as market dynamics, traffic flow, and agent-based modeling. In the future, we plan to expand our work to include other important applications of HJB equations, such as mass transport image registration and American options pricing in finance. These applications are crucial in medical imaging, computer vision, and financial modeling, and they also involve solving HJB equations but in different contexts.\r\n",
    "\r\n",
    "In this project, we focus on the numerical solution of MFGs, specifically solving the coupled HJB-KFP system. We propose using multigrid methods to solve these equations efficiently. The main challenge lies in the forward-backward duality between the HJB and KFP equations. We use Picard Fixed Point iterations to solve this system iteratively. The solution of these equations will help us better understand the optimal behavior of agents in a population and how their actions affect the collective outcome. \r\n",
    "\r\n",
    "The study of mass transport image registration and American options pricing are also important applications of HJB equations. However, we will not focus on these applications in this project but plan to address them in future work. Mass transport image registration involves aligning images using the HJB formulation of a Monge-Ampère equation, while American options pricing involves using HJB equations in the context of optimal stopping problems. We will extend the methods developed for MFGs to these other problems in future studies.\r\n",
    "\r\n",
    "### Basic Equations:\r\n",
    "- **Mean Field Games (MFGs)**:\r\n",
    "  - Hamilton-Jacobi-Bellman (HJB) equation:\r\n",
    "    $$\r\n",
    "    \\frac{\\partial V}{\\partial t} + \\frac{1}{2} \\| \\nabla V \\|^2 + H(x, \\nabla V, m) = 0, \\quad \\text{for } t \\in [0,T]\r\n",
    "    $$\r\n",
    "  - Kolmogorov-Fokker-Planck (KFP) equation:\r\n",
    "    $$\r\n",
    "    \\frac{\\partial m}{\\partial t} - \\nabla \\cdot \\left( m(x,t) \\nabla H(x, \\nabla V, m) \\right) = 0, \\quad \\text{for } t \\in [0,T]\r\n",
    "    $$\r\n",
    "\r\n",
    "In the future, we plan to implement the following applications:\r\n",
    "- **Mass Transport Image Registration**:\r\n",
    "  - Monge-Ampère equation (converted to HJB form):\r\n",
    "    $$\r\n",
    "    \\det(\\nabla^2 \\phi(x)) = \\rho(x), \\quad x \\in \\mathbb{R}^d\r\n",
    "    $$\r\n",
    "\r\n",
    "- **American Options Pricing**:\r\n",
    "  - HJB equation for American options:\r\n",
    "    $$\r\n",
    "    \\frac{\\partial V}{\\partial t} + \\frac{1}{2} \\sigma^2 \\frac{\\partial^2 V}{\\partial x^2} + rV - \\max(K - x, 0) = 0, \\quad \\text{for } t \\in [0,T]\r\n",
    "    $$\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "AP43Jq3CFrR6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73f86182652b4056f26270c1819c32b4",
     "grade": false,
     "grade_id": "cell-cf3ab00000465969",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": true,
    "id": "NKG1laSdFrR7",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0da0870c2fa4c6e72b6e6b9b3485b47e",
     "grade": true,
     "grade_id": "cell-a11d878ca3210c53",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "\n",
    "\r\n",
    "1. [MFGLib GitHub Repository](https://github.com/radar-research-lab/MFGLib/tree/main)\r\n",
    "2. [HJB Solver GitHub Repository](https://github.com/GregorDeCillia/HJB-solver)\r\n",
    "3. [Mean Field Games Numerical Methods - ODL23 Vanguard Lecture 2](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://mlauriere.github.io/teaching/MFGNUM-ODL23Vanguard-Lec2.pdf)\r\n",
    "4. [ISOTACE Beamer Slides](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://project.inria.fr/isotace/files/2013/02/beamer_slides_dauphine.pdf)\r\n",
    "5. [Workshop on Numerics for MFGs - Thomas Bourany](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://thomasbourany.github.io/files/Workshop_Numerics_MFGs_TBourany_wpause.pdf)\r\n",
    "6. [Numerical Methods for Mean Field Games - University of Waterloo](https://uwspace.uwaterloo.ca/items/f71e5095-3359-4227-b159-3fb5ce0382f4)\r\n",
    "7. [Numerical Methods for Mean Field Games - SIAM](https://epubs.siam.org/doi/10.1137/090758477)\r\n",
    "e/main)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3RG4SOMqFrR7",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e396f126d4b6f079f26afe85c99d53e",
     "grade": false,
     "grade_id": "cell-a7a4255dfbbc98e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Computational  Methods [5 pts]\n",
    "\n",
    "Describe the specific approach you will take to solve some concrete aspect of the general problem.\n",
    "\n",
    "You should  include all the numerical or computational methods you intend to use.  These can include methods or packages  we did not discuss in class but provide some reference to the method. You do not need to explain in detail how the methods work, but you should describe their basic functionality and justify your choices.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "YfNKReD3FrR7",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba61017590a5e99d3c35121cfc680136",
     "grade": true,
     "grade_id": "cell-fe71c0040eae7d5d",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "### Computational Methods\r\n",
    "\r\n",
    "To solve the problem of Mean Field Games (MFGs), we will implement a computational approach that primarily focuses on solving the Hamilton-Jacobi-Bellman (HJB) and Kolmogorov-Fokker-Planck (KFP) equations. The main numerical method we will use is Picard Fixed Point Iteration, which is ideal for solving nonlinear systems of equations that arise in MFGs.\r\n",
    "\r\n",
    "For discretization, we will utilize finite difference methods to approximate the HJB and KFP equations. The spatial domain will be discretized on a uniform grid, and time steps will be chosen adaptively to ensure stability. The general form of the HJB equation is:\r\n",
    "\r\n",
    "$$\r\n",
    "\\frac{\\partial V}{\\partial t} + \\min_{u \\in U} \\left\\{ \\mathcal{L}_u V(x,t) + f(x,t,u) \\right\\} = 0\r\n",
    "$$\r\n",
    "\r\n",
    "where $V(x,t)$ represents the value function, $u$ is the control, $\\mathcal{L}_u$ is the controlled differential operator, and $f(x,t,u)$ is the running cost. Similarly, the KFP equation, which models the evolution of the density of agents in MFGs, is given by:\r\n",
    "\r\n",
    "$$\r\n",
    "\\frac{\\partial m}{\\partial t} + \\nabla \\cdot (m \\nabla H(x,t)) = 0\r\n",
    "$$\r\n",
    "\r\n",
    "where $m(x,t)$ is the density function of agents, and $H(x,t)$ is the Hamiltonian associated with the system.\r\n",
    "\r\n",
    "To enhance computational efficiency, we will implement a multigrid method for solving the discretized systems, which improves convergence rates and reduces computational time compared to traditional methods. The multigrid method will be implemented with a novel approach where artificial viscosity is subtracted from the coarse grid operators, leading to more accurate coarse grid error estimations.\r\n",
    "\r\n",
    "We will also employ the `MFGLib` library, which provides efficient tools for solving MFGs, and the `HJB-solver` repository to aid in implementing the numerical solution of HJB equations. These libraries offer pre-built functions and optimizations specifically designed for solving such equations in the context of MFGs.\r\n",
    "\r\n",
    "The implementation will be focused on the Mean Field Games case, but methods for mass transport image registration and American options pricing will be explored in future extensions of the project.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c2w4Y3G-FrR7",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9bfbac8a8b59723bad5399bef5ac3a9",
     "grade": false,
     "grade_id": "cell-92a6ea193d5ce960",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**If you need to install or import any additional python packages,  please provide complete installation instructions in the code block below**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9AzrdyzwFrR7"
   },
   "outputs": [],
   "source": [
    "# Provide complete installation or import information for external packages or modules here e.g.\n",
    "\n",
    "#pip install somepackage\n",
    "# from somepackage import blah\n",
    "import numpy as np\n",
    "import scipy\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "i15NLtHaFrR8",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "330fc22635a3cd0732b5bf73223b75c2",
     "grade": false,
     "grade_id": "cell-501a9781d3f83013",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Implementation [60 pts]\n",
    "\n",
    "Use the Markdown and Code blocks below to implement and document your methods including figures.  Only the first markdown block will be a grading cell but please add (not copy) cells in this section to organize your work.\n",
    "\n",
    "Please make the description of your problem readable by interlacing clear explanatory text with code (again with proper grammar and spelling).\n",
    "All code should be well described and commented.\n",
    "\n",
    "For at least one routine you code below, you should provide a test block (e.g. using `numpy.testing` routines, or a convergence plot) to validate your code.  \n",
    "\n",
    "An **important** component of any computational paper is to demonstrate to yourself and others that your code is producing correct results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": true,
    "id": "JtH3wNL_FrR8",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "11b06e8b1b9fcac0845c1a031f41bc01",
     "grade": true,
     "grade_id": "cell-31f08d5d85bd9afd",
     "locked": false,
     "points": 60,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Numerical Methods for HJB Equations and Mean Field Games Implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtoDyXJQFrR8"
   },
   "source": [
    "## Hamilton-Jacobi-Bellman (HJB) Equations\r\n",
    "\r\n",
    "The goal of this thesis is to propose numerical methods for solving **HJB equations**, which are nonlinear controlled partial differential equations (PDEs) arising from **optimal control theory**.\r\n",
    "\r\n",
    "Consider a dynamical system where a controller, starting at state $ (x, t) $, controls the future evolution of the state via a control variable $ c $, aiming to optimize a cumulative objective function. For example, in a competitive smartphone market, a company sets its smartphone price (control variable) based on its current capacity (state) to maximize long-term profit (objective function).\r\n",
    "\r\n",
    "We are interested in two key quantities:\r\n",
    "1. **Value function** $ u(x, t) $, which represents the optimal objective function.\r\n",
    "2. **Optimal control** $ c^*(x, t) $, which maximizes the objective function.\r\n",
    "\r\n",
    "An HJB equation models this system by coupling the value function $ u(x, t) $ and the optimal control $ c^*(x, t) $ as follows:\r\n",
    "\r\n",
    "1. **HJB Equation**:\r\n",
    "   $$\r\n",
    "   L_{c^*}(x,t) u(x, t) = 0,\r\n",
    "   $$\r\n",
    "   where $ L $ is a second-order differential operator acting on $ u(x, t) $.\r\n",
    "\r\n",
    "2. **Optimal Control Condition**:\r\n",
    "   $$\r\n",
    "   c^*(x, t) = \\arg \\max_{c(x,t)} H(x, t; c(x,t); u(x,t)),\r\n",
    "   $$\r\n",
    "   where $ H $ is the **Hamiltonian**, and optimizing it is equivalent to solving the dynamic programming problem.\r\n",
    "\r\n",
    "The HJB equation couples two sub-problems:\r\n",
    "- A **PDE**, where the solution is the value function $ u(x, t) $ for a given optimal control $ c^*(x, t) $.\r\n",
    "- An **optimization problem** to find the control $ c(x,t) $ that optimizes the Hamiltonian.\r\n",
    "\r\n",
    "Solving the HJB equation gives both the value function $ u(x, t) $ and the optimal control $ c^*(x, t) $ simultaneously.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9RoDrrxFrR9"
   },
   "source": [
    "## Mean Field Games (MFG)\n",
    "\n",
    "Mean Field Games (MFG) are a subfield of game theory in continuous spacetime, where a large number of players interact in a competitive setting. A typical example is the competitive smartphone market, where each company optimizes its pricing strategy (control) based on its current state.\n",
    "\n",
    "When there are many companies, the system becomes extremely complex, with each company's actions affecting all others. However, as the number of companies \\( N \\) becomes large, each company’s impact on the entire system becomes negligible, simplifying the model. In this \"mean field\" approximation, companies respond to the average behavior (distribution) of other companies, rather than to individual actions.\n",
    "\n",
    "Mathematically, this leads to a system of two nonlinear PDEs:\n",
    "1. A **Hamilton-Jacobi-Bellman (HJB) equation** for the value function of all players.\n",
    "2. A **Kolmogorov-Fokker-Planck (KFP) equation** for the distribution of the players’ states.\n",
    "\n",
    "This MFG model provides a good approximation of the original \\( N \\)-player game when \\( N \\) is large, greatly simplifying the system. MFGs have numerous applications, including in economics, sociology, engineering, and urban planning, where large populations of agents interact under competitive conditions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgDgBKBAFrR9"
   },
   "source": [
    "## Introduction to Mean Field Games Theory\n",
    "\n",
    "We fix a finite time horizon $T > 0$ and work in the state space $\\mathbb{R}^d$. Let $f: \\mathbb{R}^d \\times \\mathbb{R} \\times \\mathbb{R}^d \\to \\mathbb{R}$ and $\\varphi: \\mathbb{R} \\times \\mathbb{R} \\to \\mathbb{R}$ be the running cost and terminal cost, respectively.\n",
    "\n",
    "### The Mean Field Game Problem\n",
    "We seek a flow of probability densities $\\hat{m}$ and a feedback control $\\hat{v}$ that satisfy the following conditions:\n",
    "1. **Control Problem**: Minimize the cost functional $J_{\\hat{m}}(v)$ for a feedback control $v$:\n",
    "   $$\n",
    "   J_{\\hat{m}}(v) = \\mathbb{E} \\left[ \\int_0^T f(X_v(t), \\hat{m}(t, X_v(t)), v(t, X_v(t))) \\, dt + \\varphi(X_v(T), \\hat{m}(T, X_v(T))) \\right]\n",
    "   $$\n",
    "2. **Stochastic Dynamics**: The process $X_v(t)$ solves the SDE:\n",
    "   $$\n",
    "   dX_v(t) = b(X_v(t), \\hat{m}(t, X_v(t)), v(t, X_v(t))) \\, dt + \\sigma dW_t\n",
    "   $$\n",
    "   where $\\sigma > 0$, and $X_v(0)$ is distributed according to $m_0$.\n",
    "\n",
    "3. **Density Constraint**: $\\hat{m}(t, \\cdot)$ is the law of $X_v(t)$.\n",
    "\n",
    "### Kolmogorov-Fokker-Planck Equation\n",
    "For a given feedback control $v$, the density $m_v(t)$ of $X_v(t)$ solves the KFP equation:\n",
    "$$\n",
    "\\partial_t m_v(t, x) - \\nu \\Delta m_v(t, x) + \\text{div}(m_v(t, \\cdot) b(\\cdot, m_v(t, \\cdot), v(t, \\cdot))) = 0\n",
    "$$\n",
    "where $\\nu = \\frac{\\sigma^2}{2}$.\n",
    "\n",
    "### Value Function and HJB Equation\n",
    "The value function $u(t, x)$ of the control problem satisfies the HJB equation:\n",
    "$$\n",
    "\\partial_t u(t, x) + \\nu \\Delta u(t, x) - H(x, m(t, x), \\nabla u(t, x)) = 0\n",
    "$$\n",
    "with the Hamiltonian:\n",
    "$$\n",
    "H(x, m, p) = \\sup_{\\gamma \\in \\mathbb{R}^d} \\left( - f(x, m, \\gamma) - \\langle b(x, m, \\gamma), p \\rangle \\right)\n",
    "$$\n",
    "where we assume $H$ is well-defined, $C^1$ with respect to $(x, p)$, and strictly convex in $p$.\n",
    "\n",
    "### Forward-Backward PDE System\n",
    "The system of equations for $(u, m)$ is:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "- \\partial_t u(t, x) - \\nu \\Delta u(t, x) + H(x, m(t, x), \\nabla u(t, x)) &= 0 \\\\\n",
    "\\partial_t m(t, x) - \\nu \\Delta m(t, x) - \\text{div}\\left( m(t, \\cdot) \\partial_p H(\\cdot, m(t, \\cdot), \\nabla u(t, \\cdot)) \\right) &= 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "with boundary conditions:\n",
    "$$\n",
    "u(T, x) = \\varphi(x, m(T, x)), \\quad m(0, x) = m_0(x)\n",
    "$$\n",
    "\n",
    "This forward-backward system describes the dynamics of both the optimal control and the distribution of agents in a Mean Field Game.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqhqTGbcFrR-"
   },
   "source": [
    "Let $N_T$ and $N_h$ be two positive integers. We consider $N_T + 1$ points in time and $N_h$ points in space. Define the time step $\\Delta t = \\frac{T}{N_T}$ and the spatial step $h = \\frac{1}{N_h - 1}$, with $t_n = n \\cdot \\Delta t$ and $x_i = i \\cdot h$ for $(n, i) \\in \\{0, \\dots, N_T\\} \\times \\{0, \\dots, N_h - 1\\}$.\n",
    "\n",
    "We approximate the functions $u$ and $m$ by vectors $U$ and $M$ in $\\mathbb{R}^{(N_T + 1) \\times N_h}$, so that:\n",
    "$$\n",
    "u(t_n, x_i) \\approx U_{n,i}, \\quad m(t_n, x_i) \\approx M_{n,i}, \\quad \\forall (n, i) \\in \\{0, \\dots, N_T\\} \\times \\{0, \\dots, N_h - 1\\}.\n",
    "$$\n",
    "\n",
    "To handle **Neumann boundary conditions**, we introduce **ghost nodes** at $x_{-1} = -h$ and $x_{N_h} = 1 + h$, and set:\n",
    "$$\n",
    "U_{n,-1} = U_{n,0}, \\quad U_{n,N_h} = U_{n,N_h-1}, \\quad M_{n,-1} = M_{n,0}, \\quad M_{n,N_h} = M_{n,N_h-1}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67limxV3FrR-"
   },
   "source": [
    "## Finite Differences Operators\n",
    "\n",
    "We introduce the following finite difference operators:\n",
    "\n",
    "- **First derivative with respect to time**:\n",
    "  $$\n",
    "  \\partial_t w(t_n, x) \\leftrightarrow (D_t W)_n = \\frac{W_{n+1} - W_n}{\\Delta t}, \\quad n \\in \\{0, \\dots, N_T - 1\\}, \\quad W \\in \\mathbb{R}^{N_T + 1}\n",
    "  $$\n",
    "\n",
    "- **First derivative with respect to space**:\n",
    "  $$\n",
    "  \\partial_x w(t, x) \\leftrightarrow (D_x W)_i = \\frac{W_{i+1} - W_i}{h}, \\quad i \\in \\{0, \\dots, N_h - 1\\}, \\quad W \\in \\mathbb{R}^{N_h}\n",
    "  $$\n",
    "\n",
    "- **Second derivative with respect to space**:\n",
    "  $$\n",
    "  \\partial_x^2 w(t, x) \\leftrightarrow (\\Delta_h W)_i = \\frac{W_{i+1} - 2W_i + W_{i-1}}{h^2}, \\quad i \\in \\{0, \\dots, N_h - 1\\}, \\quad W \\in \\mathbb{R}^{N_h}\n",
    "  $$\n",
    "\n",
    "- **Gradient in space**:\n",
    "  $$\n",
    "  [\\nabla_h W]_i = \\left( (D_x W)_i, (D_x W)_{i-1} \\right), \\quad i \\in \\{0, \\dots, N_h - 1\\}, \\quad W \\in \\mathbb{R}^{N_h}\n",
    "  $$\n",
    "\n",
    "These operators can be represented in matrix form. Consider a matrix $W \\in \\mathbb{R}^{(N_T + 1) \\times N_h}$, we have:\n",
    "\n",
    "- **First derivative with respect to space**:\n",
    "\n",
    "  $$\n",
    "  \\partial_x(t_n, x_i) \\quad (0 \\leq n \\leq N_T, \\, 0 \\leq i \\leq N_h - 1) \\leftrightarrow \\frac{1}{h}\n",
    "  \\begin{pmatrix}\n",
    "  -1 & 1 & 0 & \\cdots & 0 \\\\\n",
    "  0 & -1 & 1 & \\cdots & 0 \\\\\n",
    "  0 & 0 & -1 & 1 & \\cdots \\\\\n",
    "  \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "  0 & 0 & \\cdots & 0 & -1 & 1 \\\\\n",
    "  0 & 0 & \\cdots & 0 & 0 & 0\n",
    "  \\end{pmatrix}\n",
    "  \\begin{pmatrix}\n",
    "  W_0^0 & W_1^0 & \\cdots & W_{N_T}^0 \\\\\n",
    "  W_0^1 & W_1^1 & \\cdots & W_{N_T}^1 \\\\\n",
    "  \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "  W_0^{N_h-1} & W_1^{N_h-1} & \\cdots & W_{N_T}^{N_h-1}\n",
    "  \\end{pmatrix}\n",
    "  $$\n",
    "\n",
    "  In the last row, we take into account the **Neumann boundary conditions**, considering that $U_{N_h} = U_{N_h-1}$ and $M_{N_h} = M_{N_h-1}$. Let $D_x$ be the matrix above.\n",
    "\n",
    "- **Second derivative with respect to space**:\n",
    "\n",
    "  $$\n",
    "  \\partial_x^2(t_n, x_i) \\quad (0 \\leq n \\leq N_T, \\, 0 \\leq i \\leq N_h - 1) \\leftrightarrow \\frac{1}{h^2}\n",
    "  \\begin{pmatrix}\n",
    "  -1 & 1 & 0 & \\cdots & 0 \\\\\n",
    "  1 & -2 & 1 & 0 & \\cdots \\\\\n",
    "  0 & 1 & -2 & 1 & \\cdots \\\\\n",
    "  \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "  0 & 0 & \\cdots & -2 & 1 \\\\\n",
    "  0 & 0 & \\cdots & 1 & -1\n",
    "  \\end{pmatrix}\n",
    "  \\begin{pmatrix}\n",
    "  W_0^0 & W_1^0 & \\cdots & W_{N_T}^0 \\\\\n",
    "  W_0^1 & W_1^1 & \\cdots & W_{N_T}^1 \\\\\n",
    "  \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "  W_0^{N_h-1} & W_1^{N_h-1} & \\cdots & W_{N_T}^{N_h-1}\n",
    "  \\end{pmatrix}\n",
    "  $$\n",
    "\n",
    "  Denote the matrix above as $D_x^2$.\n",
    "\n",
    "- **Gradient operator**:\n",
    "\n",
    "  The matrix corresponding to $((D_x W)_i) = \\frac{1}{h} (W_i - W_{i-1})$ for $0 \\leq i < N_h$ (due to the Neumann boundary conditions) is:\n",
    "  \n",
    "  $$\n",
    "  \\frac{1}{h}\n",
    "  \\begin{pmatrix}\n",
    "  0 & 0 & 0 & \\cdots & 0 \\\\\n",
    "  -1 & 1 & 0 & \\cdots & 0 \\\\\n",
    "  0 & -1 & 1 & \\cdots & 0 \\\\\n",
    "  \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "  0 & 0 & \\cdots & 1 & 0 \\\\\n",
    "  0 & 0 & \\cdots & -1 & 1\n",
    "  \\end{pmatrix}\n",
    "  $$\n",
    "\n",
    "These finite difference operators are used to approximate the derivatives in both time and space, and they take into account the Neumann boundary conditions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNibFiCSFrR-"
   },
   "source": [
    "## Solving the HJB Equation\n",
    "\n",
    "To derive a discrete version of the HJB equation, we need to define a discrete version of the Hamiltonian. We model \\( H_0(x, p) = \\frac{1}{\\beta} |p|^\\beta - g(x) \\) as:\n",
    "$$\n",
    "\\tilde{H}(x, p_1, p_2) = \\frac{1}{\\beta} \\left( (p_1)^2 + (p_2)^2 \\right) + \\frac{\\beta}{2} - g(x)\n",
    "$$\n",
    "where \\( x^+ = \\max(0, x) \\) and \\( x^- = \\max(0, -x) \\). Note that \\( \\tilde{H} \\) takes three arguments instead of two.\n",
    "\n",
    "Now, we consider the following discrete version of the HJB equation, which includes Neumann boundary conditions and a terminal condition:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "- (D_t U_i)_n - \\nu ( \\Delta_h U_n )_i + \\tilde{H} \\left( x_i, [\\nabla_h U_n]_i \\right) &= \\tilde{f}_0(M_{n+1, i}), \\quad 0 \\leq i < N_h, \\ 0 \\leq n < N_T \\\\\n",
    "U_{n,-1} &= U_{n, 0}, \\quad 0 \\leq n < N_T \\\\\n",
    "U_{n, N_h} &= U_{n, N_h-1}, \\quad 0 \\leq n < N_T \\\\\n",
    "U_{N_T, i} &= \\varphi(x_i, M_{N_T, i}), \\quad 0 \\leq i < N_h\n",
    "\\end{aligned}\n",
    "$$\n",
    "This scheme uses an **implicit Euler scheme**, as the equation is backward in time. Given \\( M_{n+1} \\) and \\( U_{n+1} \\), we solve for \\( U_n \\). To solve this, we introduce the function:\n",
    "$$\n",
    "F(U_n, U_{n+1}, M_{n+1}) := \\begin{pmatrix}\n",
    "-(D_t U_0)_n - \\nu (\\Delta_h U_n)_0 + \\tilde{H}(x_0, [\\nabla_h U_n]_0) - \\tilde{f}_0(M_{n+1, 0}) \\\\\n",
    "-(D_t U_i)_n - \\nu (\\Delta_h U_n)_i + \\tilde{H}(x_i, [\\nabla_h U_n]_i) - \\tilde{f}_0(M_{n+1, i}) \\\\\n",
    "\\vdots \\\\\n",
    "-(D_t U_{N_h-1})_n - \\nu (\\Delta_h U_n)_{N_h-1} + \\tilde{H}(x_{N_h-1}, [\\nabla_h U_n]_{N_h-1}) - \\tilde{f}_0(M_{n+1, N_h-1})\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "When solving the HJB equation, our goal is to find \\( U_n \\) given \\( U_{n+1} \\) and \\( M_{n+1} \\). The terminal condition \\( U_{N_T, i} = \\varphi(M_{N_T, i}) \\) allows initialization for \\( n = N_T \\).\n",
    "\n",
    "For \\( n < N_T \\), we use **Newton-Raphson iterations**, which involves estimating \\( U_n \\) as the limit of a sequence \\( (U_{n,k})_k \\), defined by:\n",
    "$$\n",
    "U_{n,k+1} = U_{n,k} - J^{-1}(U_{n,k}, U_{n+1}, M_{n+1}) F(U_{n,k}, U_{n+1}, M_{n+1})\n",
    "$$\n",
    "where \\( J^{-1}(V, U_{n+1}, M_{n+1}) \\) is the Jacobian of the map \\( V \\mapsto F(V, U_{n+1}, M_{n+1}) \\). We initialize \\( U_{n,0} = U_{n+1} \\), and stop the Newton iterations when \\( \\| F(U_{n,k}, U_{n+1}, M_{n+1}) \\| \\) is below a threshold (e.g., \\( 10^{-12} \\)).\n",
    "\n",
    "### Closed Form of the Jacobian\n",
    "\n",
    "Let \\( F_i \\) be the \\( i \\)-th coordinate of \\( F(U_n, U_{n+1}, M_{n+1}) \\). The Jacobian is defined as:\n",
    "$$\n",
    "J(V, U_{n+1}, M_{n+1}) = \\begin{pmatrix}\n",
    "\\frac{\\partial F_0}{\\partial V_0} & \\frac{\\partial F_0}{\\partial V_1} & \\cdots & \\frac{\\partial F_0}{\\partial V_{N_h-1}} \\\\\n",
    "\\frac{\\partial F_1}{\\partial V_0} & \\frac{\\partial F_1}{\\partial V_1} & \\cdots & \\frac{\\partial F_1}{\\partial V_{N_h-1}} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial F_{N_h-1}}{\\partial V_0} & \\frac{\\partial F_{N_h-1}}{\\partial V_1} & \\cdots & \\frac{\\partial F_{N_h-1}}{\\partial V_{N_h-1}}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "Notice that \\( F_i \\) is given by:\n",
    "$$\n",
    "F_i = -(D_t U_i)_n - \\nu (\\Delta_h U_n)_i + \\tilde{H}(x_i, [\\nabla_h U_n]_i) - \\tilde{f}_0(M_{n+1, i})\n",
    "$$\n",
    "This term depends only on \\( U_{n,i-1}, U_{n,i}, U_{n,i+1} \\), so the Jacobian is tridiagonal. Additionally, we have:\n",
    "$$\n",
    "\\frac{\\partial F_i}{\\partial U_{n,i-1}} = - \\frac{\\nu}{h^2} - \\frac{1}{h^\\beta} \\left( (U_{n,i} - U_{n,i-1}) + \\left( (U_{n,i+1} - U_{n,i})^2 - (U_{n,i} - U_{n,i-1})^2 \\right)^{\\beta/2 - 1} \\right)\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial F_i}{\\partial U_{n,i}} = \\frac{1}{\\Delta t} + \\frac{2\\nu}{h^2} + \\frac{1}{h^\\beta} \\left( (U_{n,i+1} - U_{n,i}) + (U_{n,i} - U_{n,i-1}) \\right) \\left( \\left( (U_{n,i+1} - U_{n,i})^2 - (U_{n,i} - U_{n,i-1})^2 \\right)^{\\beta/2 - 1} \\right)\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial F_i}{\\partial U_{n,i+1}} = - \\frac{\\nu}{h^2} - \\frac{1}{h^\\beta} \\left( (U_{n,i+1} - U_{n,i}) - \\left( (U_{n,i+1} - U_{n,i})^2 - (U_{n,i} - U_{n,i-1})^2 \\right)^{\\beta/2 - 1} \\right)\n",
    "$$\n",
    "\n",
    "Let \\( J_H \\) be the Jacobian of \\( U_n \\mapsto \\tilde{H}(x_i, [\\nabla_h U_n]_i) \\), evaluated at \\( U_n \\), which will be useful in the sequel. The coefficients of \\( J_H \\) are:\n",
    "$$\n",
    "(J_H)_{i,i-1} = - \\frac{1}{h^\\beta} \\left( (U_{n,i} - U_{n,i-1}) + \\left( (U_{n,i+1} - U_{n,i})^2 - (U_{n,i} - U_{n,i-1})^2 \\right)^{\\beta/2 - 1} \\right)\n",
    "$$\n",
    "$$\n",
    "(J_H)_{i,i} = \\frac{1}{h^\\beta} \\left( (U_{n,i+1} - U_{n,i}) + (U_{n,i} - U_{n,i-1}) \\right) \\left( \\left( (U_{n,i+1} - U_{n,i})^2 - (U_{n,i} - U_{n,i-1})^2 \\right)^{\\beta/2 - 1} \\right)\n",
    "$$\n",
    "$$\n",
    "(J_H)_{i,i+1} = - \\frac{1}{h^\\beta} \\left( (U_{n,i+1} - U_{n,i}) - \\left( (U_{n,i+1} - U_{n,i})^2 - (U_{n,i} - U_{n,i-1})^2 \\right)^{\\beta/2 - 1} \\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTmCM4TsFrR_"
   },
   "source": [
    "## Solving the KFP Equation\n",
    "\n",
    "To define an appropriate discretization of the KFP equation, we first discuss how to discretize the term:\n",
    "$$\n",
    "\\partial_x \\left( m(t, \\cdot) \\partial_x u(t, \\cdot) \\right)^{\\beta-2} \\partial_x u(t, \\cdot) (x).\n",
    "$$\n",
    "Recall that:\n",
    "$$\n",
    "\\partial_x \\left( m(t, \\cdot) \\partial_p H_0(x, \\partial_x u(t, x)) \\right) \\quad \\text{}\n",
    "$$\n",
    "Let us consider a smooth function \\( w \\in C^\\infty([0, T] \\times \\Omega) \\). Using integration by parts and recalling **Neumann boundary conditions**, we get:\n",
    "$$\n",
    "- \\int_\\Omega \\partial_x \\left( m(t, x) \\partial_p H_0(x, \\partial_x u(t, x)) \\right) w(t, x) \\, dx = \\int_\\Omega m(t, x) \\partial_p H_0(x, \\partial_x u(t, x)) \\partial_x w(t, x) \\, dx.\n",
    "$$\n",
    "\n",
    "We now propose the following approximation of the right-hand side:\n",
    "$$\n",
    "\\sum_{i=0}^{N_h - 1} M_{n+1, i} \\left[ \\frac{\\partial p_1 \\tilde{H}(x_i, [\\nabla_h U_n]_i)}{h} (W_{n,i+1} - W_{n,i}) + \\frac{\\partial p_2 \\tilde{H}(x_i, [\\nabla_h U_n]_i)}{h} (W_{n,i} - W_{n,i-1}) \\right] \\quad \\text{}\n",
    "$$\n",
    "\n",
    "Performing discrete integration by parts, we obtain the discrete counterpart of the left-hand side as:\n",
    "$$\n",
    "-h \\sum_{i=0}^{N_h-1} T_i(U_n, M_{n+1}) W_{n,i},\n",
    "$$\n",
    "where \\( T_i(U, M) \\) is defined as:\n",
    "$$\n",
    "T_i(U, M) = \\frac{1}{h} \\left( M_i \\frac{\\partial p_1 \\tilde{H}(x_i, [\\nabla_h U_n]_i)}{\\partial x_i} - M_{i-1} \\frac{\\partial p_1 \\tilde{H}(x_{i-1}, [\\nabla_h U_n]_{i-1})}{\\partial x_{i-1}} \\right),\n",
    "$$\n",
    "and similarly for the second term:\n",
    "$$\n",
    "+ \\frac{1}{h} \\left( M_{i+1} \\frac{\\partial p_2 \\tilde{H}(x_{i+1}, [\\nabla_h U_n]_{i+1})}{\\partial x_{i+1}} - M_i \\frac{\\partial p_2 \\tilde{H}(x_i, [\\nabla_h U_n]_i)}{\\partial x_i} \\right).\n",
    "$$\n",
    "\n",
    "We now consider the following discrete version of the KFP equation, supplemented with **Neumann conditions** and the **terminal condition**:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "(D_t M_i)_n - \\nu (\\Delta_h M_{n+1})_i - T_i(U_n, M_{n+1}) &= 0, \\quad 0 \\leq i < N_h, \\quad 0 \\leq n < N_T \\\\\n",
    "M_{n,-1} &= M_{n,0}, \\quad 0 < n \\leq N_T \\\\\n",
    "M_{n, N_h} &= M_{n, N_h-1}, \\quad 0 < n \\leq N_T \\\\\n",
    "M_0(i) &= \\bar{m}_0(x_i), \\quad 0 \\leq i < N_h\n",
    "\\end{aligned}\n",
    "$$\n",
    "where:\n",
    "$$\n",
    "\\bar{m}_0(x_i) = \\int_{|x - x_i| \\leq h/2} m_0(x) \\, dx \\quad \\text{or} \\quad \\bar{m}_0(x_i) = m_0(x_i).\n",
    "$$\n",
    "\n",
    "This scheme is implicit, but unlike the HJB scheme, it involves a **forward loop**. Starting from time step \\( 0 \\), \\( M_0(i) = \\bar{m}_0(x_i) \\) provides an explicit formula for \\( M_0 \\). At each subsequent time step, \\( M_{n+1} \\) is computed given \\( U_n \\) and \\( M_n \\). The KFP system  is linear and cant-hand side term derived from the initial and boundary conditions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FF3pToBJFrR_"
   },
   "source": [
    "## Solving the Whole Forward-Backward System\r\n",
    "\r\n",
    "The idea is to use **Picard fixed point iterations** to compute the sequences $ M := (M_n)_{0 \\leq n \\leq N_T} $ and $ U := (U_n)_{0 \\leq n \\leq N_T} $.\r\n",
    "\r\n",
    "Let $ 0 < \\theta < 1 $ be a parameter (for instance, $ \\theta = 0.01 $). Let $ (M^{(k)}, U^{(k)}) $ represent the running approximations of $ (M, U) $. The next approximation $ (M^{(k+1)}, U^{(k+1)}) $ is computed as follows:\r\n",
    "\r\n",
    "1. **Solve the discrete HJB equation** given $ (M^{(k)}, U^{(k)}) $. The solution is denoted $ \\hat{U}^{(k+1)} $.\r\n",
    "2. **Solve the discrete KFP equation** given $ (M^{(k)}, \\hat{U}^{(k+1)}) $. The solution is denoted $ \\hat{M}^{(k+1)} $.\r\n",
    "3. **Update the approximations**:\r\n",
    "   $$\r\n",
    "   (M^{(k+1)}, U^{(k+1)}) = (1 - \\theta)(M^{(k)}, U^{(k)}) + \\theta(M^{(k+1)}, U^{(k+1)}).\r\n",
    "   $$\r\n",
    "\r\n",
    "The iterations are stopped when the norm of the increment $ (M^{(k+1)}, U^{(k+1)}) - (M^{(k)}, U^{(k)}) $ becomes smaller than a given threshold, say $ 10^{-7} $.\r\n",
    "\r\n",
    "### Initialization\r\n",
    "\r\n",
    "- For the initialization, we set $ M^{(0)}_{n,i} = \\bar{m}_0(x_i) $ for all $ 0 \\leq i < N_h $ and $ 0 \\leq n \\leq N_T $.\r\n",
    "- The initial matrix $ U^{(0)} $ has minimal impact on the convergence of the algorithm. We set $ U^{(0)}_{n,i} = 0 $ for all $ i, n $.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multigrid Methods\n",
    "\n",
    "To efficiently solve the system, we propose a multigrid method applied over the entire spacetime. Previous methods use block Jacobi iterations as smoothers, but they are not ideal. They require solving multiple blocks at each step, which is costly, and are less effective than other smoothers like Gauss-Seidel.\n",
    "\n",
    "Some methods use linearization to solve the problem, but these are not fully nonlinear and rely on iterating over linear approximations. The multigrid approach we propose also uses outer nonlinear iterations (like Newton's method) and inner multigrid cycles to improve efficiency. However, the total number of iterations may still be large due to this layered structure.\n",
    "\n",
    "In summary, the multigrid method combines linearization and smoothing to efficiently solve the system, but it requires multiple iterations, and it is not fully nonlinear.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "YV_Yzo_aFrSA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def solve_equations(T=1, sigma=0.2, beta=2, N_h=201, N_T=100, g_kind='default', phi_kind='default', f0_tilde_kind='thin', theta=0.5, picard_stopping_criteria=1e-3, newton_stopping_criteria=1e-11):\n",
    "    \"\"\"\n",
    "    Solves the mean field game using the Hamilton-Jacobi-Bellman (HJB) and Kolmogorov Forward Equation (KFP) via Picard iteration.\n",
    "\n",
    "    Parameters:\n",
    "        T: Total time horizon.\n",
    "        sigma: Volatility parameter for the model.\n",
    "        beta: Risk aversion coefficient.\n",
    "        N_h: Number of grid points in space.\n",
    "        N_T: Number of time steps.\n",
    "        g_kind: Type of cost function.\n",
    "        phi_kind: Type of potential function.\n",
    "        f0_tilde_kind: Type of f0 modification.\n",
    "        theta: Relaxation parameter for Picard iteration.\n",
    "        picard_stopping_criteria: Convergence tolerance for Picard iteration.\n",
    "        newton_stopping_criteria: Convergence tolerance for Newton-Raphson method.\n",
    "\n",
    "    Returns:\n",
    "        Plots of the solution for the HJB and KFP equations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set model parameters and grid resolution\n",
    "    volatility = sigma**2 / 2  # volatility (nu)\n",
    "    time_step = T / N_T  # time step\n",
    "    space_step = 1 / (N_h - 1)  # space step\n",
    "    time_grid = np.arange(0, T + time_step, time_step)  # time grid\n",
    "    space_grid = np.arange(0, 1 + space_step, space_step)  # space grid\n",
    "\n",
    "    # Model-related functions\n",
    "    def cost_function(x, kind=g_kind):\n",
    "        \"\"\"\n",
    "        Computes the cost function g(x) based on the chosen type (g_kind).\n",
    "        Different forms of g(x) can be specified.\n",
    "        \"\"\"\n",
    "        if kind == 'default':\n",
    "            return -np.exp(-40 * (x - 0.5) ** 2)  # Gaussian centered at x=0.5\n",
    "        elif kind == 'complex':\n",
    "            return -np.exp(-40 * (x - 1/3) ** 2) - np.exp(-40 * (x - 2/3) ** 2)  # Sum of two Gaussians at x=1/3 and x=2/3\n",
    "\n",
    "    def Hamiltonian_function(x, p1, p2):\n",
    "        \"\"\"\n",
    "        Computes the Hamiltonian H(x, p1, p2) for the model based on x, p1, and p2.\n",
    "        Returns the Hamiltonian, which includes the cost function and other terms.\n",
    "        \"\"\"\n",
    "        return 1 / beta * ((np.minimum(0, p1)) ** 2 + (np.maximum(0, p2)) ** 2) ** (beta / 2) - cost_function(x)\n",
    "\n",
    "    def modified_f0_function(m, kind=f0_tilde_kind):\n",
    "        \"\"\"\n",
    "        Modifies the function f0 based on the specified type (f0_tilde_kind).\n",
    "        Different modifications are applied depending on the kind chosen.\n",
    "        \"\"\"\n",
    "        if kind == 'thin':\n",
    "            return m / 10  # Scaling factor for 'thin'\n",
    "        elif kind == 'large':\n",
    "            return m * 10  # Scaling factor for 'large'\n",
    "\n",
    "    def potential_function(x, m=None, kind=phi_kind):\n",
    "        \"\"\"\n",
    "        Computes the potential function phi(x) based on the chosen kind (phi_kind).\n",
    "        Different forms of phi(x) can be specified.\n",
    "        \"\"\"\n",
    "        if kind == 'default':\n",
    "            return -np.exp(-40 * (x - 0.7) ** 2)  # Gaussian centered at x=0.7\n",
    "        elif kind == 'complex':\n",
    "            return -np.exp(-40 * (x - 0.3) ** 2) - np.exp(-40 * (x - 0.9) ** 2)  # Sum of two Gaussians\n",
    "\n",
    "    def initial_condition_function(x):\n",
    "        \"\"\"\n",
    "        Returns the initial condition for m(x) as a Gaussian centered at x=0.2.\n",
    "        \"\"\"\n",
    "        return np.exp(-3000 * (x - 0.2) ** 2)\n",
    "\n",
    "    def m_initial_function(x):\n",
    "        \"\"\"\n",
    "        Returns the initial condition for m(x), based on the initial condition function.\n",
    "        \"\"\"\n",
    "        return initial_condition_function(x)\n",
    "\n",
    "    # Discretized differential operators (used for numerical solutions)\n",
    "\n",
    "    # First spatial derivative (forward difference)\n",
    "    Dx = np.diag([-1] * N_h) + np.diag([1] * (N_h - 1), k=1)\n",
    "    Dx[N_h - 1, N_h - 1] = 0\n",
    "    Dx = Dx / space_step\n",
    "\n",
    "    # First spatial derivative (backward difference)\n",
    "    Dx_shift = np.diag([1] * N_h) + np.diag([-1] * (N_h - 1), k=-1)\n",
    "    Dx_shift[0, 0] = 0\n",
    "    Dx_shift = Dx_shift / space_step\n",
    "\n",
    "    # Second spatial derivative (central difference)\n",
    "    Dx2 = np.diag([-2] * N_h) + np.diag([1] * (N_h - 1), k=1) + np.diag([1] * (N_h - 1), k=-1)\n",
    "    Dx2[0, 0], Dx2[N_h - 1, N_h - 1] = -1, -1\n",
    "    Dx2 = Dx2 / space_step ** 2\n",
    "\n",
    "    # Matrix computation for the Newton's method residual\n",
    "    def compute_residual(U_next, U_now, M):\n",
    "        \"\"\"\n",
    "        Computes the residual term F for the Newton-Raphson iteration.\n",
    "        The residual depends on the time step, spatial derivatives, and cost functions.\n",
    "        \"\"\"\n",
    "        residual = -(U_next - U_now) / time_step - volatility * Dx2 @ U_now\n",
    "        residual += 1 / beta * (np.minimum(Dx @ U_now, 0) ** 2 + (np.maximum(Dx_shift @ U_now, 0)) ** 2) ** (beta / 2)\n",
    "        residual += -cost_function(space_grid) - modified_f0_function(M)\n",
    "        return residual\n",
    "\n",
    "    # Compute Jacobian matrix for the Newton-Raphson method\n",
    "    def compute_Jacobian(U):\n",
    "        \"\"\"\n",
    "        Computes the Jacobian matrix for the residual in the Newton-Raphson method.\n",
    "        This matrix accounts for spatial derivatives and the functional form of the Hamiltonian.\n",
    "        \"\"\"\n",
    "        backward_spatial_diff = np.maximum(Dx_shift @ U, 0)\n",
    "        forward_spatial_diff = -np.minimum(Dx @ U, 0)\n",
    "        coef = backward_spatial_diff ** 2 + forward_spatial_diff ** 2\n",
    "        coef = np.power(coef, beta / 2 - 1, out=np.zeros_like(coef), where=(coef != 0))\n",
    "\n",
    "        main_diag = (1 / space_step * (forward_spatial_diff + backward_spatial_diff) * coef)\n",
    "        sub_diag = (-1 / space_step * backward_spatial_diff * coef)[1:]\n",
    "        sup_diag = (-1 / space_step * forward_spatial_diff * coef)[:-1]\n",
    "        jacobian = np.diag(sub_diag, k=-1) + np.diag(main_diag) + np.diag(sup_diag, k=+1)\n",
    "\n",
    "        return jacobian\n",
    "\n",
    "    # Compute banded Jacobian matrix for more efficient computations\n",
    "    def compute_banded_jacobian(U):\n",
    "        \"\"\"\n",
    "        Computes a banded version of the Jacobian matrix for the Newton-Raphson method.\n",
    "        The banded matrix format is more efficient for large systems.\n",
    "        \"\"\"\n",
    "        backward_spatial_diff = np.maximum(Dx_shift @ U, 0)\n",
    "        forward_spatial_diff = -np.minimum(Dx @ U, 0)\n",
    "        coef = backward_spatial_diff ** 2 + forward_spatial_diff ** 2\n",
    "        coef = np.power(coef, beta / 2 - 1, out=np.zeros_like(coef), where=(coef != 0))\n",
    "\n",
    "        sub_diag = (-1 / space_step * backward_spatial_diff * coef)[1:]\n",
    "        main_diag = (1 / space_step * (forward_spatial_diff + backward_spatial_diff) * coef)\n",
    "        sup_diag = (-1 / space_step * forward_spatial_diff * coef)[:-1]\n",
    "\n",
    "        banded_matrix = np.zeros((3, U.size))\n",
    "        banded_matrix[0, 1:] = sup_diag - volatility / space_step ** 2\n",
    "        banded_matrix[1] = main_diag + 1 / time_step + 2 * volatility / space_step ** 2\n",
    "        banded_matrix[2, :-1] = sub_diag - volatility / space_step ** 2\n",
    "        return banded_matrix\n",
    "\n",
    "    # Newton-Raphson method for solving the system\n",
    "    def newton_raphson_method(U, M):\n",
    "        \"\"\"\n",
    "        Solves the system using the Newton-Raphson method.\n",
    "        The iteration continues until the residual is smaller than the stopping criteria.\n",
    "        \"\"\"\n",
    "        U_new = U.copy()\n",
    "        residual_norm = np.inf\n",
    "        while residual_norm > newton_stopping_criteria:\n",
    "            residual = compute_residual(U, U_new, M)\n",
    "            jacobian = compute_banded_jacobian(U_new)\n",
    "            U_new = U_new - scipy.linalg.solve_banded((1, 1), jacobian, residual)\n",
    "            residual_norm = np.linalg.norm(residual)\n",
    "        return U_new\n",
    "\n",
    "    # Solving HJB equation backward in time\n",
    "    def solve_HJB_equation(M):\n",
    "        \"\"\"\n",
    "        Solves the HJB equation backward in time using the Newton-Raphson method.\n",
    "        Boundary conditions are set at the final time step using the potential function.\n",
    "        \"\"\"\n",
    "        U_solution = np.zeros(M.shape)\n",
    "        U_solution[N_T] = potential_function(space_grid)  # Initial condition at final time\n",
    "        for n in range(N_T - 1, -1, -1):\n",
    "            U_solution[n] = newton_raphson_method(U_solution[n + 1], M[n + 1])  # Solve backward in time\n",
    "        return U_solution\n",
    "\n",
    "    # Solving KFP equation forward in time\n",
    "    def solve_KFP_equation(U):\n",
    "        \"\"\"\n",
    "        Solves the KFP equation forward in time using matrix inversion at each step.\n",
    "        Updates the solution using the Jacobian matrix.\n",
    "        \"\"\"\n",
    "        M_solution = np.zeros(U.shape)\n",
    "        M_solution[0] = m_initial_function(space_grid)  # Initial condition at time 0\n",
    "        for n in range(N_T):\n",
    "            jacobian = compute_Jacobian(U[n])\n",
    "            M_solution[n + 1] = np.linalg.solve(np.identity(N_h) - volatility * time_step * Dx2 + time_step * jacobian.T, M_solution[n])\n",
    "        return M_solution\n",
    "\n",
    "    # Picard iteration method to solve the system of equations\n",
    "    def picard_iteration_method(U_old, M_old):\n",
    "        \"\"\"\n",
    "        Performs Picard iteration to solve the system of equations.\n",
    "        Alternates between solving the HJB and KFP equations until convergence.\n",
    "        \"\"\"\n",
    "        t0 = time.time()\n",
    "        k = 0\n",
    "        norm_increment = np.inf\n",
    "        print(f\"[Picard] Iteration {k}, previous norm: {norm_increment}, elapsed time: {time.time() - t0}\")\n",
    "\n",
    "        while norm_increment > picard_stopping_criteria:\n",
    "            U_new = solve_HJB_equation(M_old)\n",
    "            M_new = solve_KFP_equation(U_new)\n",
    "\n",
    "            U_updated = (1 - theta) * U_old + theta * U_new  # Update with relaxation factor\n",
    "            M_updated = (1 - theta) * M_old + theta * M_new\n",
    "\n",
    "            increment = np.hstack((U_updated - U_old, M_updated - M_old))  # Increment\n",
    "            norm_increment = np.linalg.norm(increment)\n",
    "            k += 1\n",
    "\n",
    "            U_old, M_old = U_updated, M_updated  # Update the solutions\n",
    "\n",
    "        return U_updated, M_updated\n",
    "\n",
    "    # Initializing solutions\n",
    "    M_initial = np.zeros((N_T + 1, N_h))\n",
    "    M_initial[:] = m_initial_function(space_grid)\n",
    "\n",
    "    U_initial = np.zeros((N_T + 1, N_h))\n",
    "    U_initial[:] = potential_function(space_grid)\n",
    "\n",
    "    # Perform Picard iteration to solve the system\n",
    "    U_final, M_final = picard_iteration_method(U_initial, M_initial)\n",
    "\n",
    "    # Plotting the results\n",
    "\n",
    "    # Contour plots for U and M\n",
    "    plt.contour(space_grid, time_grid, U_final, levels=20)\n",
    "    plt.title(f\"Contour lines of $U$, $\\\\beta={beta}$, $g$ kind={g_kind}, $\\\\phi$ kind={phi_kind}, $f_0$ kind={f0_tilde_kind}\")\n",
    "    plt.xlabel(\"$x$\")\n",
    "    plt.ylabel(\"$t$\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    plt.contour(space_grid, time_grid, M_final, levels=20)\n",
    "    plt.title(f\"Contour lines of $M$, $\\\\beta={beta}$, $g$ kind={g_kind}, $\\\\phi$ kind={phi_kind}, $f_0$ kind={f0_tilde_kind}\")\n",
    "    plt.xlabel(\"$x$\")\n",
    "    plt.ylabel(\"$t$\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # 3D surface plots for U and M\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot for U\n",
    "    ax = fig.add_subplot(121, projection='3d')\n",
    "    X, T = np.meshgrid(space_grid, time_grid)\n",
    "    ax.plot_surface(X, T, U_final, cmap='viridis', edgecolor='none')\n",
    "    ax.set_title(f\"3D Surface Plot of $U$, $\\\\beta={beta}$, $g$ kind={g_kind}, $\\\\phi$ kind={phi_kind}, $f_0$ kind={f0_tilde_kind}\")\n",
    "    ax.set_xlabel(\"Space ($x$)\")\n",
    "    ax.set_ylabel(\"Time ($t$)\")\n",
    "    ax.set_zlabel(\"$U$\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Plot for M\n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    ax2.plot_surface(X, T, M_final, cmap='viridis', edgecolor='none')\n",
    "    ax2.set_title(f\"3D Surface Plot of $M$, $\\\\beta={beta}$, $g$ kind={g_kind}, $\\\\phi$ kind={phi_kind}, $f_0$ kind={f0_tilde_kind}\")\n",
    "    ax2.set_xlabel(\"Space ($x$)\")\n",
    "    ax2.set_ylabel(\"Time ($t$)\")\n",
    "    ax2.set_zlabel(\"$M$\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8LMvW-6gFrSB",
    "outputId": "73c8de41-adb6-43c8-eb74-7aea916bcfe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Picard] Iteration 0, previous norm: inf, elapsed time: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m solve_equations(beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, g_kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, phi_kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, f0_tilde_kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[27], line 225\u001b[0m, in \u001b[0;36msolve_equations\u001b[1;34m(T, sigma, beta, N_h, N_T, g_kind, phi_kind, f0_tilde_kind, theta, picard_stopping_criteria, newton_stopping_criteria)\u001b[0m\n\u001b[0;32m    222\u001b[0m U_initial[:] \u001b[38;5;241m=\u001b[39m potential_function(space_grid)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# Perform Picard iteration to solve the system\u001b[39;00m\n\u001b[1;32m--> 225\u001b[0m U_final, M_final \u001b[38;5;241m=\u001b[39m picard_iteration_method(U_initial, M_initial)\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# Plotting the results\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# Contour plots for U and M\u001b[39;00m\n\u001b[0;32m    230\u001b[0m plt\u001b[38;5;241m.\u001b[39mcontour(space_grid, time_grid, U_final, levels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "Cell \u001b[1;32mIn[27], line 204\u001b[0m, in \u001b[0;36msolve_equations.<locals>.picard_iteration_method\u001b[1;34m(U_old, M_old)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m norm_increment \u001b[38;5;241m>\u001b[39m picard_stopping_criteria:\n\u001b[0;32m    203\u001b[0m     U_new \u001b[38;5;241m=\u001b[39m solve_HJB_equation(M_old)\n\u001b[1;32m--> 204\u001b[0m     M_new \u001b[38;5;241m=\u001b[39m solve_KFP_equation(U_new)\n\u001b[0;32m    206\u001b[0m     U_updated \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m theta) \u001b[38;5;241m*\u001b[39m U_old \u001b[38;5;241m+\u001b[39m theta \u001b[38;5;241m*\u001b[39m U_new  \u001b[38;5;66;03m# Update with relaxation factor\u001b[39;00m\n\u001b[0;32m    207\u001b[0m     M_updated \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m theta) \u001b[38;5;241m*\u001b[39m M_old \u001b[38;5;241m+\u001b[39m theta \u001b[38;5;241m*\u001b[39m M_new\n",
      "Cell \u001b[1;32mIn[27], line 188\u001b[0m, in \u001b[0;36msolve_equations.<locals>.solve_KFP_equation\u001b[1;34m(U)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_T):\n\u001b[0;32m    187\u001b[0m     jacobian \u001b[38;5;241m=\u001b[39m compute_Jacobian(U[n])\n\u001b[1;32m--> 188\u001b[0m     M_solution[n \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msolve(np\u001b[38;5;241m.\u001b[39midentity(N_h) \u001b[38;5;241m-\u001b[39m volatility \u001b[38;5;241m*\u001b[39m time_step \u001b[38;5;241m*\u001b[39m Dx2 \u001b[38;5;241m+\u001b[39m time_step \u001b[38;5;241m*\u001b[39m jacobian\u001b[38;5;241m.\u001b[39mT, M_solution[n])\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m M_solution\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\linalg\\linalg.py:411\u001b[0m, in \u001b[0;36msolve\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    408\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m    409\u001b[0m r \u001b[38;5;241m=\u001b[39m gufunc(a, b, signature\u001b[38;5;241m=\u001b[39msignature, extobj\u001b[38;5;241m=\u001b[39mextobj)\n\u001b[1;32m--> 411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(r\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "solve_equations(beta=2, g_kind='default', phi_kind='default', f0_tilde_kind='thin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DvVTsb9bKvqh",
    "outputId": "1abad95f-d6f7-4057-ba68-92cc4b20ced8"
   },
   "outputs": [],
   "source": [
    "solve_equations(beta=4, g_kind='default', phi_kind='default', f0_tilde_kind='thin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4aDp6jXuFrSB",
    "outputId": "034388a8-3da7-444b-fefc-01418ab0ee82"
   },
   "outputs": [],
   "source": [
    "solve_equations(beta=2, g_kind='complex', phi_kind='default', f0_tilde_kind='thin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lxezHAXUFrSB",
    "outputId": "6ba1f18d-2728-4790-b661-681e633b4fb3"
   },
   "outputs": [],
   "source": [
    "solve_equations(beta=2, g_kind='default', phi_kind='complex', f0_tilde_kind='thin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hN7XdCb8FrSB",
    "outputId": "c286e705-7060-45ff-c8c4-93b942691989"
   },
   "outputs": [],
   "source": [
    "solve_equations(beta=2, g_kind='complex', phi_kind='complex', f0_tilde_kind='thin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3jOBCyrXFrSR"
   },
   "outputs": [],
   "source": [
    "def test_spatial_derivative():\n",
    "    \"\"\"\n",
    "    Test the spatial derivative computation by comparing numerical and analytical derivatives of a known function.\n",
    "    \"\"\"\n",
    "    # Known function (for example, a Gaussian function)\n",
    "    def known_function(x):\n",
    "        return np.exp(-40 * (x - 0.5) ** 2)\n",
    "    \n",
    "    # Analytical derivative of the known function\n",
    "    def known_function_derivative(x):\n",
    "        return -80 * (x - 0.5) * np.exp(-40 * (x - 0.5) ** 2)\n",
    "    \n",
    "    # Numerical derivative using the Dx matrix\n",
    "    space_grid = np.linspace(0, 1, 201)\n",
    "    space_step = space_grid[1] - space_grid[0]\n",
    "    Dx = np.diag([-1] * len(space_grid)) + np.diag([1] * (len(space_grid) - 1), k=1)\n",
    "    Dx = Dx / space_step\n",
    "    \n",
    "    numerical_derivative = Dx @ known_function(space_grid)\n",
    "    analytical_derivative = known_function_derivative(space_grid)\n",
    "    \n",
    "    # Compare the numerical and analytical derivatives\n",
    "    npt.assert_allclose(numerical_derivative, analytical_derivative, atol=1e-5, rtol=0.0)\n",
    "    print(\"Spatial derivative test passed!\")\n",
    "\n",
    "test_spatial_derivative()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "y705C9XHFrSS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87d6ad005559ded09934219c910ab7e3",
     "grade": false,
     "grade_id": "cell-8139016f051ab235",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Discussion [10 pts]\n",
    "\n",
    "Evaluate the results of your project including\n",
    "* Why should I believe that your numerical results are correct (convergence, test cases etc)?\n",
    "* Did the project work (in your opinion)?\n",
    "* If yes:  what would be the next steps to try\n",
    "* If no:  Explain why your approach did not work and what you might do to fix it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": true,
    "id": "3a5RwbquFrSS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9a6bc1bd11c0e30eac1ac25f6ca71bb",
     "grade": true,
     "grade_id": "cell-596162f90cd1e909",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
